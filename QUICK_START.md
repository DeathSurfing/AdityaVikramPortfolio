# âš¡ Quick Start: Ollama + Docker Compose + Cloudflare Tunnel

## ğŸ¯ What We Built

A simple Docker Compose deployment for your Ollama-powered portfolio chatbot:

```
Browser â†’ Cloudflare Tunnel â†’ Docker Container (FastAPI Proxy) â†’ Ollama â†’ AI Response
```

## ğŸš€ Quick Deployment

```bash
# 1. Start Ollama
ollama serve

# 2. Deploy with Docker Compose
cd ollama-proxy
./deploy.sh

# 3. Start Cloudflare Tunnel
cloudflared tunnel --config cloudflare-tunnel-config.yml run
```

## ğŸ”§ Manual Deployment

```bash
# Ensure Ollama is running with gpt-oss:20b model
ollama serve
ollama pull gpt-oss:20b

# Deploy with Docker Compose
cd ollama-proxy
docker compose up --build -d

# Verify deployment
curl http://localhost:5950/health
```

## ğŸŒ Cloudflare Tunnel Config

```yaml
ingress:
  # ğŸ¤– AI Chat API (Docker container)
  - hostname: portfolio.adityavikram.dev
    path: /api/*
    service: http://localhost:5950

  # ğŸŒ Portfolio Website
  - hostname: portfolio.adityavikram.dev
    service: http://localhost:8594
```

## ğŸ“ Deployment Files

```
ollama-proxy/
â”œâ”€â”€ docker-compose.yml          # ğŸ³ Main deployment config
â”œâ”€â”€ Dockerfile                  # Container definition
â”œâ”€â”€ main.py                     # FastAPI server with Ollama library
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ deploy.sh                   # Simple deployment script
```

## âœ… Features

1. **ğŸ³ Containerized**: Runs in Docker for consistent deployment
2. **ğŸ”„ CI/CD Ready**: GitHub Actions workflow included
3. **ğŸŒ Cloudflare Ready**: Works with your existing tunnel config
4. **ğŸ¤– gpt-oss:20b**: Uses your specified model
5. **âš¡ Simple**: One command deployment

## ğŸ§ª Testing

```bash
# Health check
curl http://localhost:5950/health

# Chat test
curl -X POST http://localhost:5950/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Hello! Tell me about Aditya"}'
```

## ğŸ‰ Result

Your AI assistant is now deployed and accessible at:
- **Local**: http://localhost:5950/api/chat
- **Public**: https://portfolio.adityavikram.dev/api/chat (via Cloudflare tunnel)

---

**Need help?** The deployment is now much simpler - just `docker compose up --build -d`!
