name: Deploy Ollama Proxy

on:
  push:
    branches: [ main, master ]
    paths:
      - 'ollama-proxy/**'
      - '.github/workflows/deploy-ollama-proxy.yml'
  pull_request:
    branches: [ main, master ]
    paths:
      - 'ollama-proxy/**'
  workflow_dispatch:

env:
  OLLAMA_MODEL: gpt-oss:20b
  PYTHON_VERSION: '3.13'

jobs:
  lint-and-test:
    runs-on: self-hosted
    name: 🔍 Lint & Test
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python environment
      run: |
        echo "🐍 Setting up Python environment..."
        # Check for Python versions (prefer specific versions if available)
        if command -v python3.13 &> /dev/null; then
          echo "Using python3.13"
          PYTHON_CMD=python3.13
        elif command -v python3.12 &> /dev/null; then
          echo "Using python3.12"
          PYTHON_CMD=python3.12
        elif command -v python3.11 &> /dev/null; then
          echo "Using python3.11"
          PYTHON_CMD=python3.11
        elif command -v python &> /dev/null; then
          python_version=$(python --version 2>&1 | cut -d" " -f2 | cut -d"." -f1,2)
          echo "Found Python version: $python_version"
          PYTHON_CMD=python
        elif command -v python3 &> /dev/null; then
          python_version=$(python3 --version 2>&1 | cut -d" " -f2 | cut -d"." -f1,2)
          echo "Found Python version: $python_version"
          PYTHON_CMD=python3
        else
          echo "❌ Python not found"
          exit 1
        fi
        echo "PYTHON_CMD=$PYTHON_CMD" >> $GITHUB_ENV
        
        # Verify Python version is suitable
        $PYTHON_CMD --version
        echo "✅ Python environment ready"

    - name: Install dependencies
      working-directory: ./ollama-proxy
      run: |
        echo "📦 Installing dependencies..."
        # Check if we're in a virtual environment or should use --user
        if [[ "$VIRTUAL_ENV" != "" ]] || [[ "$CONDA_DEFAULT_ENV" != "" ]]; then
            echo "ℹ️ Using virtual environment for package installation"
            $PYTHON_CMD -m pip install --upgrade pip
            $PYTHON_CMD -m pip install -r requirements.txt
            $PYTHON_CMD -m pip install black flake8 mypy bandit safety
        else
            echo "ℹ️ Installing to user site-packages"
            $PYTHON_CMD -m pip install --upgrade pip --user
            $PYTHON_CMD -m pip install -r requirements.txt --user
            $PYTHON_CMD -m pip install black flake8 mypy bandit safety --user
        fi

    - name: Code formatting check (Black)
      working-directory: ./ollama-proxy
      run: |
        echo "🎨 Checking code formatting with Black..."
        if command -v black &> /dev/null; then
          black --check --diff main.py
        else
          echo "⚠️ Black not available, skipping format check"
        fi

    - name: Lint with flake8
      working-directory: ./ollama-proxy
      run: |
        echo "🔍 Linting with flake8..."
        if command -v flake8 &> /dev/null; then
          flake8 main.py --count --select=E9,F63,F7,F82 --show-source --statistics
          flake8 main.py --count --exit-zero --max-complexity=10 --max-line-length=88 --statistics
        else
          echo "⚠️ Flake8 not available, skipping lint check"
        fi

    - name: Type checking with mypy
      working-directory: ./ollama-proxy
      run: |
        echo "📝 Type checking with mypy..."
        if command -v mypy &> /dev/null; then
          mypy main.py --ignore-missing-imports || true
        else
          echo "⚠️ MyPy not available, skipping type check"
        fi

    - name: Security scan with bandit
      working-directory: ./ollama-proxy
      run: |
        echo "🛡️ Security scanning with bandit..."
        if command -v bandit &> /dev/null; then
          bandit -r main.py -f json || true
        else
          echo "⚠️ Bandit not available, skipping security scan"
        fi

    - name: Check for known security vulnerabilities
      working-directory: ./ollama-proxy
      run: |
        echo "🚨 Checking for known vulnerabilities..."
        if command -v safety &> /dev/null; then
          safety check --json || true
        else
          echo "⚠️ Safety not available, skipping vulnerability check"
        fi

    - name: Validate Docker configuration
      working-directory: ./ollama-proxy
      run: |
        echo "🐳 Validating Docker configuration..."
        docker compose config
        hadolint Dockerfile || echo "⚠️ Hadolint not available, skipping Dockerfile lint"

  deploy:
    runs-on: self-hosted
    name: 🚀 Deploy to Runner
    needs: lint-and-test
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Check system requirements
      run: |
        echo "🔍 Checking system requirements..."
        echo "Docker version: $(docker --version)"
        echo "Docker Compose version: $(docker compose version)"
        echo "Available disk space:"
        df -h

    - name: Check if Ollama is running
      run: |
        echo "🔍 Checking Ollama status..."
        if curl -f http://localhost:11434/api/tags > /dev/null 2>&1; then
          echo "✅ Ollama is running"
          echo "📋 Available models:"
          curl -s http://localhost:11434/api/tags | jq -r '.models[].name' || echo "Could not list models"
        else
          echo "❌ Ollama is not running. Please start Ollama on the runner."
          echo "   Command: ollama serve"
          exit 1
        fi

    - name: Check/Pull model
      run: |
        echo "🔍 Checking if model ${{ env.OLLAMA_MODEL }} is available..."
        if ! curl -s http://localhost:11434/api/tags | jq -r '.models[].name' | grep -q "${{ env.OLLAMA_MODEL }}"; then
          echo "⬇️ Model ${{ env.OLLAMA_MODEL }} not found, pulling..."
          ollama pull ${{ env.OLLAMA_MODEL }}
          echo "✅ Model pulled successfully"
        else
          echo "✅ Model ${{ env.OLLAMA_MODEL }} is available"
        fi

    - name: Stop existing deployment
      working-directory: ./ollama-proxy
      run: |
        echo "🛑 Stopping existing deployment..."
        docker compose down || true
        docker system prune -f || true

    - name: Deploy with Docker Compose
      working-directory: ./ollama-proxy
      run: |
        echo "🚀 Deploying Ollama proxy with Docker Compose..."
        export OLLAMA_MODEL=${{ env.OLLAMA_MODEL }}
        docker compose up --build -d

    - name: Wait for service to be ready
      run: |
        echo "⏳ Waiting for service to be ready..."
        timeout=120
        elapsed=0
        
        while [ $elapsed -lt $timeout ]; do
          if curl -f http://localhost:5950/health > /dev/null 2>&1; then
            echo "✅ Service is ready!"
            break
          fi
          echo "   Waiting... ($elapsed/$timeout seconds)"
          sleep 10
          elapsed=$((elapsed + 10))
        done
        
        if [ $elapsed -ge $timeout ]; then
          echo "❌ Timeout waiting for service"
          echo "📋 Container logs:"
          docker compose -f ./ollama-proxy/docker-compose.yml logs
          exit 1
        fi

    - name: Comprehensive deployment test
      run: |
        echo "🧪 Running comprehensive tests..."
        
        # Test health endpoint
        echo "Testing health endpoint..."
        health_response=$(curl -s http://localhost:5950/health)
        echo "Health: $(echo $health_response | jq -r '.status')"
        
        # Test models endpoint
        echo "Testing models endpoint..."
        models_response=$(curl -s http://localhost:5950/api/models)
        model_count=$(echo $models_response | jq '.models | length')
        echo "Available models: $model_count"
        
        # Test chat endpoint
        echo "Testing chat endpoint..."
        chat_response=$(curl -s -X POST http://localhost:5950/api/chat \
          -H "Content-Type: application/json" \
          -d '{"message": "Hello! Just testing the deployment."}' \
          --max-time 30)
        
        if echo "$chat_response" | jq -e '.message' > /dev/null 2>&1; then
          echo "✅ Chat endpoint working!"
          response_length=$(echo "$chat_response" | jq -r '.message' | wc -c)
          echo "   Response length: $response_length characters"
        else
          echo "❌ Chat endpoint failed"
          echo "   Response: $chat_response"
          exit 1
        fi
        
        # Test CORS headers
        echo "Testing CORS headers..."
        cors_response=$(curl -s -I -H "Origin: https://portfolio.adityavikram.dev" \
          http://localhost:5950/health)
        if echo "$cors_response" | grep -q "Access-Control-Allow-Origin"; then
          echo "✅ CORS headers present"
        else
          echo "⚠️ CORS headers not found (might be expected for non-preflight requests)"
        fi

    - name: Container health check
      working-directory: ./ollama-proxy
      run: |
        echo "🏥 Checking container health..."
        container_status=$(docker compose ps --format json | jq -r '.[0].Health')
        echo "Container health: $container_status"
        
        if [ "$container_status" != "healthy" ] && [ "$container_status" != "null" ]; then
          echo "⚠️ Container not healthy, checking logs..."
          docker compose logs --tail 20
        fi

    - name: Clean up old images
      run: |
        echo "🧹 Cleaning up old Docker images..."
        docker image prune -f --filter "until=24h"

    - name: Deployment summary
      working-directory: ./ollama-proxy
      run: |
        echo "📊 Deployment Summary"
        echo "===================="
        echo "✅ Ollama proxy deployed successfully"
        echo "🤖 Model: ${{ env.OLLAMA_MODEL }}"
        echo "🌐 Health check: http://localhost:5950/health"
        echo "💬 Chat endpoint: http://localhost:5950/api/chat"
        echo "🔗 Ready for Cloudflare tunnel routing"
        echo ""
        echo "📋 Container status:"
        docker compose ps
        echo ""
        echo "📊 System resources:"
        df -h | grep -E '(Filesystem|/dev/)' || true
        echo "Memory usage:"
        docker stats --no-stream --format "table {{.Name}}\t{{.CPUPerc}}\t{{.MemUsage}}" || true
